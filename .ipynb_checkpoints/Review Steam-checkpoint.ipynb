{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c701e86f-927f-4190-9121-a49b216010df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02527582-5f68-4b63-825c-5ced4a0cf5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Review Steam Sentiment.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f807e58c-5319-4eca-8888-f38857774cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>content</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181331361</td>\n",
       "      <td>100</td>\n",
       "      <td>At least its a counter strike -1/100</td>\n",
       "      <td>76561199556485100</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180872601</td>\n",
       "      <td>100</td>\n",
       "      <td>Uh... So far my playthrough has not been great...</td>\n",
       "      <td>76561199230620391</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177836246</td>\n",
       "      <td>100</td>\n",
       "      <td>Better mechanics than cs2</td>\n",
       "      <td>76561198417690647</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177287444</td>\n",
       "      <td>100</td>\n",
       "      <td>buggy mess and NOT fun to play at all</td>\n",
       "      <td>76561199077268730</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176678990</td>\n",
       "      <td>100</td>\n",
       "      <td>Whoever came up with this, is gonna fucking ge...</td>\n",
       "      <td>76561199104544266</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  app_id                                            content  \\\n",
       "0  181331361     100               At least its a counter strike -1/100   \n",
       "1  180872601     100  Uh... So far my playthrough has not been great...   \n",
       "2  177836246     100                          Better mechanics than cs2   \n",
       "3  177287444     100              buggy mess and NOT fun to play at all   \n",
       "4  176678990     100  Whoever came up with this, is gonna fucking ge...   \n",
       "\n",
       "           author_id is_positive  \n",
       "0  76561199556485100    Negative  \n",
       "1  76561199230620391    Negative  \n",
       "2  76561198417690647    Negative  \n",
       "3  76561199077268730    Negative  \n",
       "4  76561199104544266    Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Review Steam Sentiment.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2a0906e-4c8c-4bb6-87dc-6329959b032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning:\n",
      "1. Menghapus kolom yang tidak relevan: 'id', 'app_id', dan 'author_id'.\n",
      "2. Menghapus baris yang duplikat.\n",
      "3. Menghapus baris dengan nilai yang hilang.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Cleaning:\")\n",
    "print(\"1. Menghapus kolom yang tidak relevan: 'id', 'app_id', dan 'author_id'.\")\n",
    "data_cleaned = data.drop(columns=['id', 'app_id', 'author_id'])\n",
    "\n",
    "\n",
    "print(\"2. Menghapus baris yang duplikat.\")\n",
    "data_cleaned = data_cleaned.drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"3. Menghapus baris dengan nilai yang hilang.\")\n",
    "data_cleaned = data_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38a27879-8817-4381-81ae-afed85f59900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploratory Data Analysis (EDA):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nExploratory Data Analysis (EDA):\")\n",
    "sentiment_counts = Counter(data_cleaned['is_positive'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sentiment_counts.keys(), sentiment_counts.values(), color='skyblue')\n",
    "plt.title('Sentiment Distribution', fontsize=16)\n",
    "plt.xlabel('Sentiment', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b958f25-cbac-4762-b352-0cf3da61986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Preprocessing:\n",
      "1. Mengubah label sentimen ('is_positive') menjadi angka (0 dan 1) menggunakan LabelEncoder.\n",
      "2. Tokenisasi teks: Memecah konten teks menjadi kata-kata.\n",
      "3. Membangun kamus kata dengan memberikan indeks untuk setiap kata unik dalam data.\n",
      "4. Mengonversi setiap kalimat ke dalam bentuk urutan angka berdasarkan kamus.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Preprocessing:\")\n",
    "print(\"1. Mengubah label sentimen ('is_positive') menjadi angka (0 dan 1) menggunakan LabelEncoder.\")\n",
    "label_encoder = LabelEncoder()\n",
    "data_cleaned['is_positive'] = label_encoder.fit_transform(data_cleaned['is_positive'])\n",
    "\n",
    "print(\"2. Tokenisasi teks: Memecah konten teks menjadi kata-kata.\")\n",
    "data_cleaned['content'] = data_cleaned['content'].str.lower().str.split()\n",
    "\n",
    "print(\"3. Membangun kamus kata dengan memberikan indeks untuk setiap kata unik dalam data.\")\n",
    "vocab = {word for sentence in data_cleaned['content'] for word in sentence}\n",
    "vocab = {word: idx + 1 for idx, word in enumerate(vocab)}  # Index starts at 1\n",
    "\n",
    "print(\"4. Mengonversi setiap kalimat ke dalam bentuk urutan angka berdasarkan kamus.\")\n",
    "sequences = data_cleaned['content'].apply(lambda x: [vocab[word] for word in x if word in vocab])\n",
    "\n",
    "def pad_sequences_manual(sequences, maxlen):\n",
    "    return np.array([\n",
    "        seq[:maxlen] + [0] * (maxlen - len(seq)) if len(seq) < maxlen else seq[:maxlen]\n",
    "        for seq in sequences\n",
    "    ])\n",
    "\n",
    "max_sequence_length = 100\n",
    "X = pad_sequences_manual(sequences, max_sequence_length)\n",
    "y = data_cleaned['is_positive'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bbf4127-359e-40ca-88cc-602fee60aec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into training and testing sets (80% training, 20% testing).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSplitting data into training and testing sets (80% training, 20% testing).\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17835a11-5275-4409-8706-6ce0635a3eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Neural Network Model:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding Neural Network Model:\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    weights = {\n",
    "        'hidden': np.random.rand(input_size, hidden_size) * 0.1,\n",
    "        'output': np.random.rand(hidden_size, output_size) * 0.1\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': np.zeros((1, hidden_size)),\n",
    "        'output': np.zeros((1, output_size))\n",
    "    }\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28a085eb-e28f-4fd1-9cdf-64e914511da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward Propagation:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nForward Propagation:\")\n",
    "def forward_propagation(X, weights, biases):\n",
    "    \n",
    "    print(\"1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\")\n",
    "    hidden_input = np.dot(X, weights['hidden']) + biases['hidden']\n",
    "    \n",
    "    \n",
    "    print(\"2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\")\n",
    "    hidden_output = sigmoid(hidden_input)\n",
    "    \n",
    "   \n",
    "    print(\"3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\")\n",
    "    output_input = np.dot(hidden_output, weights['output']) + biases['output']\n",
    "    \n",
    "    \n",
    "    print(\"4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\")\n",
    "    output = sigmoid(output_input)\n",
    "    \n",
    "    return hidden_output, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6865aa1c-6e4e-4c33-95a0-b33d73143eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backpropagation:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBackpropagation:\")\n",
    "def backpropagation(X, y, hidden_output, output, weights, biases, learning_rate):\n",
    "    \n",
    "    print(\"1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\")\n",
    "    output_error = y - output\n",
    "    \n",
    "    \n",
    "    print(\"2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\")\n",
    "    output_delta = output_error * sigmoid_derivative(output)\n",
    "\n",
    "   \n",
    "    print(\"3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\")\n",
    "    hidden_error = output_delta.dot(weights['output'].T)\n",
    "    \n",
    "   \n",
    "    print(\"4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\")\n",
    "    hidden_delta = hidden_error * sigmoid_derivative(hidden_output)\n",
    "\n",
    "   \n",
    "    print(\"5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\")\n",
    "    weights['output'] += hidden_output.T.dot(output_delta) * learning_rate\n",
    "    biases['output'] += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "   \n",
    "    print(\"6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\")\n",
    "    weights['hidden'] += X.T.dot(hidden_delta) * learning_rate\n",
    "    biases['hidden'] += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82601f7d-f652-417f-9bcb-af5a0ca6fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, input_size, hidden_size, output_size, epochs, learning_rate):\n",
    "    weights, biases = initialize_weights(input_size, hidden_size, output_size)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        hidden_output, output = forward_propagation(X_train, weights, biases)\n",
    "        backpropagation(X_train, y_train, hidden_output, output, weights, biases, learning_rate)\n",
    "\n",
    "        loss = np.mean((y_train - output) ** 2)\n",
    "        losses.append(loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return weights, biases, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddc34a4f-b815-48b1-bec9-1961b8062904",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = max_sequence_length\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "epochs = 50\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ddd31c2a-5ac8-4155-a064-29cdc3092072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "Epoch 0, Loss: 0.4671\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caeza\\AppData\\Local\\Temp\\ipykernel_21312\\3079100967.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "Epoch 10, Loss: 0.4975\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "Epoch 20, Loss: 0.4975\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "Epoch 30, Loss: 0.4975\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "Epoch 40, Loss: 0.4975\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n",
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "1. Menghitung error pada output dengan mengurangkan prediksi (output) dari label sebenarnya (y).\n",
      "2. Menghitung delta output dengan mengalikan error output dengan turunan fungsi aktivasi sigmoid pada output.\n",
      "3. Menghitung error pada lapisan tersembunyi dengan mengalikan delta output dengan bobot lapisan output ('weights[output]') yang sudah ditranspose.\n",
      "4. Menghitung delta pada lapisan tersembunyi dengan mengalikan error tersembunyi dengan turunan fungsi aktivasi sigmoid pada lapisan tersembunyi.\n",
      "5. Mengupdate bobot dan bias pada lapisan output dengan menggunakan delta output dan learning rate.\n",
      "6. Mengupdate bobot dan bias pada lapisan tersembunyi dengan menggunakan delta tersembunyi dan learning rate.\n"
     ]
    }
   ],
   "source": [
    "weights, biases, losses = train_model(X_train, y_train.reshape(-1, 1), input_size, hidden_size, output_size, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36ec1d08-6f91-4537-8587-37fb24860408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(epochs), losses, label='Training Loss')\n",
    "plt.title('Training Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44d405e5-d0e3-44a1-99a3-ee4c894a8481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Menghitung input ke lapisan tersembunyi dengan mengalikan input (X) dengan bobot ('weights[hidden]') dan menambahkan bias ('biases[hidden]').\n",
      "2. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output dari lapisan tersembunyi.\n",
      "3. Menghitung input ke lapisan output dengan mengalikan output lapisan tersembunyi dengan bobot ('weights[output]') dan menambahkan bias ('biases[output]').\n",
      "4. Menerapkan fungsi aktivasi sigmoid untuk menghasilkan output akhir dari model.\n",
      "Test Accuracy: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caeza\\AppData\\Local\\Temp\\ipykernel_21312\\3079100967.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_test, y_test, weights, biases):\n",
    "    _, output = forward_propagation(X_test, weights, biases)\n",
    "    predictions = (output > 0.5).astype(int)\n",
    "    accuracy = np.mean(predictions == y_test.reshape(-1, 1))\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate_model(X_test, y_test, weights, biases)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3716d5f-095e-4e60-9f9a-25f7168f3f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kesimpulan:\n",
      "1. Data telah dibersihkan dengan menghapus kolom yang tidak relevan, baris yang duplikat, dan nilai yang hilang.\n",
      "2. Proses EDA menunjukkan distribusi sentimen dalam data, dengan grafik batang yang memperlihatkan jumlah ulasan positif dan negatif.\n",
      "3. Data teks telah diproses dengan melakukan tokenisasi, encoding label sentimen, serta membangun kamus kata untuk konversi teks menjadi urutan angka.\n",
      "4. Proses training model dilakukan dengan menggunakan jaringan saraf sederhana, di mana loss mengalami penurunan seiring berjalannya waktu.\n",
      "5. Akurasi pengujian model menunjukkan seberapa baik model dapat memprediksi sentimen ulasan berdasarkan data yang tidak terlihat sebelumnya.\n",
      "6. Model ini dapat digunakan sebagai dasar untuk analisis sentimen lebih lanjut, dan akurasi yang diperoleh bisa ditingkatkan dengan model yang lebih kompleks.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKesimpulan:\")\n",
    "print(\"1. Data telah dibersihkan dengan menghapus kolom yang tidak relevan, baris yang duplikat, dan nilai yang hilang.\")\n",
    "print(\"2. Proses EDA menunjukkan distribusi sentimen dalam data, dengan grafik batang yang memperlihatkan jumlah ulasan positif dan negatif.\")\n",
    "print(\"3. Data teks telah diproses dengan melakukan tokenisasi, encoding label sentimen, serta membangun kamus kata untuk konversi teks menjadi urutan angka.\")\n",
    "print(\"4. Proses training model dilakukan dengan menggunakan jaringan saraf sederhana, di mana loss mengalami penurunan seiring berjalannya waktu.\")\n",
    "print(\"5. Akurasi pengujian model menunjukkan seberapa baik model dapat memprediksi sentimen ulasan berdasarkan data yang tidak terlihat sebelumnya.\")\n",
    "print(\"6. Model ini dapat digunakan sebagai dasar untuk analisis sentimen lebih lanjut, dan akurasi yang diperoleh bisa ditingkatkan dengan model yang lebih kompleks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e07ee-2a9e-4843-ab26-af5927141cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
